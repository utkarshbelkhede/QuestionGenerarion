{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7DFNSwyfFuu"
   },
   "source": [
    "Author: **Ramsri Goutham Golla**  [Linkedin](https://www.linkedin.com/in/ramsrig/)   [Twitter](https://twitter.com/ramsri_goutham/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BERT Word Sense Disambiguation is adapted from the awesome repo here. [BERT WSD](https://github.com/BPYap/BERT-WSD) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvo1s6FWjn6s"
   },
   "source": [
    "## Installation and mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4q45GmGwVbT",
    "outputId": "33b2cd16-7c74-4555-c094-ba40866d4419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==2.9.0 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (2.9.0)\n",
      "Requirement already satisfied: sacremoses in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (0.0.53)\n",
      "Requirement already satisfied: requests in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (2.28.1)\n",
      "Requirement already satisfied: filelock in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (2022.7.25)\n",
      "Requirement already satisfied: sentencepiece in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (0.1.97)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (4.64.0)\n",
      "Requirement already satisfied: numpy in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (1.21.6)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from transformers==2.9.0) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from requests->transformers==2.9.0) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from requests->transformers==2.9.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from requests->transformers==2.9.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from requests->transformers==2.9.0) (3.3)\n",
      "Requirement already satisfied: joblib in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from sacremoses->transformers==2.9.0) (1.1.0)\n",
      "Requirement already satisfied: six in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from sacremoses->transformers==2.9.0) (1.16.0)\n",
      "Requirement already satisfied: click in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from sacremoses->transformers==2.9.0) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from click->sacremoses->transformers==2.9.0) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.9.0) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==2.9.0) (4.3.0)\n",
      "Requirement already satisfied: nltk==3.4.5 in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages (from nltk==3.4.5) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.9.0\n",
    "!pip install nltk==3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.13\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uccuJrda4qay"
   },
   "source": [
    "## Generate distractors (wrong choices) for MCQ options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R07mVhsI4w45",
    "outputId": "e7bb9bc5-6b88-4407-c34d-794b78d7274c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/utkarsh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "sentence1 = \"Srivatsan loves to watch cricket during his free time\"\n",
    "sentence2 = \"Srivatsan is annoyed by a cricket in his room\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLt3WH3X5gJp",
    "outputId": "00824908-897f-4720-9d57-6fc96eaf581a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cricket.n.01') :  leaping insect; male makes chirping noises by rubbing the forewings together \n",
      "\n",
      "Synset('cricket.n.02') :  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# An example of a word with two different senses\n",
    "original_word = \"cricket\"\n",
    "\n",
    "syns = wn.synsets(original_word,'n')\n",
    "\n",
    "for syn in syns:\n",
    "  print (syn, \": \",syn.definition(),\"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nsxh1ZjF5d-j",
    "outputId": "6e27b346-a077-49e5-a5fe-f45326640a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original word:  Cricket\n",
      "['Grasshopper']\n",
      "\n",
      "original word:  Cricket\n",
      "['Ball Game', 'Field Hockey', 'Football', 'Hurling', 'Lacrosse', 'Polo', 'Pushball', 'Ultimate Frisbee']\n"
     ]
    }
   ],
   "source": [
    "# Distractors from Wordnet\n",
    "def get_distractors_wordnet(syn,word):\n",
    "    distractors=[]\n",
    "    word= word.lower()\n",
    "    orig_word = word\n",
    "    if len(word.split())>0:\n",
    "        word = word.replace(\" \",\"_\")\n",
    "    hypernym = syn.hypernyms()\n",
    "    if len(hypernym) == 0: \n",
    "        return distractors\n",
    "    for item in hypernym[0].hyponyms():\n",
    "        name = item.lemmas()[0].name()\n",
    "        #print (\"name \",name, \" word\",orig_word)\n",
    "        if name == orig_word:\n",
    "            continue\n",
    "        name = name.replace(\"_\",\" \")\n",
    "        name = \" \".join(w.capitalize() for w in name.split())\n",
    "        if name is not None and name not in distractors:\n",
    "            distractors.append(name)\n",
    "    return distractors\n",
    "\n",
    "\n",
    "synset_to_use = wn.synsets(original_word,'n')[0]\n",
    "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
    "\n",
    "print (\"\\noriginal word: \",original_word.capitalize())\n",
    "print (distractors_calculated)\n",
    "\n",
    "\n",
    "original_word = \"cricket\"\n",
    "synset_to_use = wn.synsets(original_word,'n')[1]\n",
    "distractors_calculated = get_distractors_wordnet(synset_to_use,original_word)\n",
    "\n",
    "print (\"\\noriginal word: \",original_word.capitalize())\n",
    "print (distractors_calculated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neRbWQhO4GnG"
   },
   "source": [
    "## Download pretrained BERT WSD Model and extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rELsk4JIMhJ3"
   },
   "source": [
    "Download pre-trained BERT WSD from [here](https://entuedu-my.sharepoint.com/:f:/g/personal/boonpeng001_e_ntu_edu_sg/EiWzblOyyOBDtuO3klUbXoAB3THFzke-2MLWguIXrDopWg?e=08umXD)\n",
    "\n",
    "Click the download button at the top left of the link to download a file named \"bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
    "\n",
    "Place the zip file in your Google drive home folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "MNz0zFZzrXqN",
    "outputId": "0bf7ec35-53be-4017-be8c-3f284e8e815a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/utkarsh/PycharmProjects/QuestionGenerarion/model  is extracted already\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "bert_wsd_pytorch = \"/home/utkarsh/PycharmProjects/QuestionGenerarion/model.zip\"\n",
    "extract_directory = \"/content/gdrive/MyDrive/Question Generation\"\n",
    "\n",
    "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n",
    "\n",
    "#  If unzipped folder exists don't unzip again.\n",
    "if not os.path.isdir(extracted_folder):\n",
    "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n",
    "      zip_ref.extractall(extract_directory)\n",
    "else:\n",
    "  print (extracted_folder,\" is extracted already\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GtYSH2ewtO4"
   },
   "source": [
    "## Find the correct sense (contextual meaning) of a given word in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "EnmszaP9zSpe",
    "outputId": "44343cea-35c2-44a4-de45-360aad129417"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertWSD(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n",
    "\n",
    "\n",
    "class BertWSD(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "# def _forward(args, model, batch):\n",
    "#     batch = tuple(t.to(args.device) for t in batch)\n",
    "#     outputs = model.bert(input_ids=batch[0], attention_mask=batch[1], token_type_ids=batch[2])\n",
    "\n",
    "#     return model.dropout(outputs[1])\n",
    "    \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_dir = \"/home/utkarsh/PycharmProjects/QuestionGenerarion/model/model\"\n",
    "\n",
    "\n",
    "model = BertWSD.from_pretrained(model_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
    "# add new special token\n",
    "if '[TGT]' not in tokenizer.additional_special_tokens:\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n",
    "    assert '[TGT]' in tokenizer.additional_special_tokens\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0bWxo4vFUfH",
    "outputId": "8970fbe2-4091-483d-bfc9-2f60f017b126"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/utkarsh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from collections import namedtuple\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n",
    "BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n",
    "\n",
    "\n",
    "\n",
    "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n",
    "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
    "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
    "                                  cls_token_segment_id=1, pad_token_segment_id=0,\n",
    "                                  mask_padding_with_zero=True, disable_progress_bar=False):\n",
    "    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\n",
    "        always the feature created from context-gloss pair while the rest of the elements are features created from\n",
    "        context-example pairs (if available)\n",
    "        `cls_token_at_end` define the location of the CLS token:\n",
    "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for record in tqdm(records, disable=disable_progress_bar):\n",
    "        tokens_a = tokenizer.tokenize(record.sentence)\n",
    "\n",
    "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n",
    "\n",
    "        pairs = []\n",
    "        for seq, label in sequences:\n",
    "            tokens_b = tokenizer.tokenize(seq)\n",
    "\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "\n",
    "            # The convention in BERT is:\n",
    "            # (a) For sequence pairs:\n",
    "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "            #\n",
    "            # Where \"type_ids\" are used to indicate whether this is the first\n",
    "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "            # embedding vector (and position vector). This is not *strictly* necessary\n",
    "            # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "            # it easier for the model to learn the concept of sequences.\n",
    "            #\n",
    "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "            # the entire model is fine-tuned.\n",
    "            tokens = tokens_a + [sep_token]\n",
    "            segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "            tokens += tokens_b + [sep_token]\n",
    "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
    "\n",
    "            if cls_token_at_end:\n",
    "                tokens = tokens + [cls_token]\n",
    "                segment_ids = segment_ids + [cls_token_segment_id]\n",
    "            else:\n",
    "                tokens = [cls_token] + tokens\n",
    "                segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding_length = max_seq_length - len(input_ids)\n",
    "            if pad_on_left:\n",
    "                input_ids = ([pad_token] * padding_length) + input_ids\n",
    "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "            else:\n",
    "                input_ids = input_ids + ([pad_token] * padding_length)\n",
    "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "\n",
    "            pairs.append(\n",
    "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n",
    "            )\n",
    "\n",
    "        features.append(pairs)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM09g5ljMJDp"
   },
   "source": [
    "![picture](https://drive.google.com/uc?export=view&id=1rVyHMMl0YoQrQO8aLD54prOIKIlmzwT0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJSpZRuOF-52",
    "outputId": "827bd37c-54ff-4bb2-e55a-b25b06c0564e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Srivatsan loves to watch **cricket** during his free time\n",
      "Synset('cricket.n.02')\n",
      "a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n",
      "\n",
      "-------------------------------\n",
      "Srivatsan is annoyed by a **cricket** in his room\n",
      "Synset('cricket.n.01')\n",
      "leaping insect; male makes chirping noises by rubbing the forewings together\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from tabulate import tabulate\n",
    "from torch.nn.functional import softmax\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer\n",
    "import time\n",
    "\n",
    "\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "def get_sense(sent):\n",
    "  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\n",
    "  if re_result is None:\n",
    "      print(\"\\nIncorrect input format. Please try again.\")\n",
    "\n",
    "  ambiguous_word = re_result.group(1).strip()\n",
    "\n",
    "  results = dict()\n",
    "\n",
    "  wn_pos = wn.NOUN\n",
    "  for i, synset in enumerate(set(wn.synsets(ambiguous_word, pos=wn_pos))):\n",
    "      results[synset] =  synset.definition()\n",
    "\n",
    "  if len(results) ==0:\n",
    "    return (None,None,ambiguous_word)\n",
    "\n",
    "  # print (results)\n",
    "  sense_keys=[]\n",
    "  definitions=[]\n",
    "  for sense_key, definition in results.items():\n",
    "      sense_keys.append(sense_key)\n",
    "      definitions.append(definition)\n",
    "\n",
    "\n",
    "  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\n",
    "\n",
    "  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
    "                                            cls_token=tokenizer.cls_token,\n",
    "                                            sep_token=tokenizer.sep_token,\n",
    "                                            cls_token_segment_id=1,\n",
    "                                            pad_token_segment_id=0,\n",
    "                                            disable_progress_bar=True)[0]\n",
    "\n",
    "  with torch.no_grad():\n",
    "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
    "      # for i, bert_input in tqdm(list(enumerate(features)), desc=\"Progress\"):\n",
    "      for i, bert_input in list(enumerate(features)):\n",
    "          logits[i] = model.ranking_linear(\n",
    "              model.bert(\n",
    "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
    "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
    "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "              )[1]\n",
    "          )\n",
    "      scores = softmax(logits, dim=0)\n",
    "\n",
    "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
    "\n",
    "\n",
    "  # print (preds)\n",
    "  sense = preds[0][0]\n",
    "  meaning = preds[0][1]\n",
    "  return (sense,meaning,ambiguous_word)\n",
    "\n",
    "\n",
    "sentence1 = \"Srivatsan loves to watch **cricket** during his free time\"\n",
    "\n",
    "\n",
    "sentence_for_bert = sentence1.replace(\"**\",\" [TGT] \")\n",
    "sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
    "sense,meaning,answer = get_sense(sentence_for_bert)\n",
    "\n",
    "print (sentence1)\n",
    "print (sense)\n",
    "print (meaning)\n",
    "\n",
    "sentence2 = \"Srivatsan is annoyed by a **cricket** in his room\"\n",
    "sentence_for_bert = sentence2.replace(\"**\",\" [TGT] \")\n",
    "sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
    "sense,meaning,answer = get_sense(sentence_for_bert)\n",
    "\n",
    "print (\"\\n-------------------------------\")\n",
    "print (sentence2)\n",
    "print (sense)\n",
    "print (meaning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwg3jDQJYKCh"
   },
   "source": [
    "## Generate a question using context and answer with T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAdXVQN8YfED"
   },
   "source": [
    "![picture](https://drive.google.com/uc?export=view&id=1Dc6W3F__okw1q6GxhKs46lvgeeBsP0iG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "6a94fafe03024a6eaad37959ae64cc73",
      "142d016eb8214aa28f19be6b4fbca339",
      "1f66d75ab094423d99bb4648b1290698",
      "fae887e257514fbb801c0c5d331f57c6",
      "2de42e44240b463f905735646ec5abfd",
      "e309f41ad5184122a86aec00b02ff626",
      "00a5c4c124024b71818660fc555d916d",
      "6c0840f318024ab9a16fd99fe8767fd3",
      "d3fbc0d0728148e3a08dc882bbfc3ef4",
      "c5aef9f69ad94c0287ee688fdd10bbb3",
      "179becad93544a29b2741191f8bec893",
      "411d08235cbc429283405673051f88c5",
      "ba839dd8d584448e880b1a2a19554d8f",
      "7063e4b4cfc24887a83a354033d20a29",
      "e421731c8412433091e58699d9214628",
      "16678cc9ab1a4ba1bc1da2c8a9bde9b6",
      "704a5be7508e47449bdc1161a5fe8cd4",
      "cd5f9302f6284729857f408842194ea4",
      "07624b5f2dcc40228c6a97a81de3ac3e",
      "4d592c9566f34af9aea2c4d1575fed8d",
      "a18e76af94ab4101bde6ccb1ba1b3da4",
      "6e48c134789c4200a3143b077628faed",
      "9b093515743d4e69b216834573f96602",
      "f910423ef6e143d1a8a7d95be91bd1b3",
      "9dbed6d8b4b04194beb3da32d358927d",
      "f4ab9ebc94d84300a0c13ce2b8c93fea",
      "0ce1aafc7ed94eaca3809367cb9e2696",
      "49fae8c6167b4e2481e73682075e37a6",
      "df4c9d848f5c4e0eb29e098e7695c695",
      "36a27f29392d4083b8e49c16081d59d0",
      "9e6c30f8f75249019d52dd9323421b2e",
      "c729906924654cf5b6ce0f4332db20d9",
      "554bf9faea064f91b95e50a0d45ed377"
     ]
    },
    "id": "wyazTS9RJ46n",
    "outputId": "7ad2f250-a700-4427-f252-ee85b3db18a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Srivatsan loves to watch cricket during his free time answer: cricket </s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages/transformers/modeling_utils.py:1432: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  beam_id = beam_token_id // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What sport does Srivatsan enjoy watching?\n",
      "\n",
      "**************************************\n",
      "\n",
      "context: Srivatsan is annoyed by a cricket in his room answer: cricket </s>\n",
      "What insect is in Srivatsan's room?\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "def get_question(sentence,answer):\n",
    "  text = \"context: {} answer: {} </s>\".format(sentence,answer)\n",
    "  print (text)\n",
    "  max_len = 256\n",
    "  encoding = question_tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "\n",
    "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "  outs = question_model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=1,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  max_length=200)\n",
    "\n",
    "\n",
    "  dec = [question_tokenizer.decode(ids) for ids in outs]\n",
    "\n",
    "\n",
    "  Question = dec[0].replace(\"question:\",\"\")\n",
    "  Question= Question.strip()\n",
    "  return Question\n",
    "\n",
    "\n",
    "sentence1 = \"Srivatsan loves to watch **cricket** during his free time\"\n",
    "sentence2 = \"Srivatsan is annoyed by a **cricket** in his room\"\n",
    "\n",
    "\n",
    "answer = \"cricket\"\n",
    "\n",
    "sentence_for_T5 = sentence1.replace(\"**\",\" \")\n",
    "sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
    "ques = get_question(sentence_for_T5,answer)\n",
    "print (ques)\n",
    "\n",
    "\n",
    "print (\"\\n**************************************\\n\")\n",
    "sentence_for_T5 = sentence2.replace(\"**\",\" \")\n",
    "sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
    "ques = get_question(sentence_for_T5,answer)\n",
    "print (ques)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jQ1QK_zYCFu"
   },
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKbPKBjr-KTp",
    "outputId": "f32552c4-7226-4080-dc67-6e79ab5fae52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "context: Srivatsan loves to watch cricket during his free time answer: cricket </s>\n",
      "What sport does Srivatsan enjoy watching?\n",
      "cricket\n",
      "['Ball Game', 'Field Hockey', 'Football', 'Hurling', 'Lacrosse', 'Polo', 'Pushball', 'Ultimate Frisbee']\n",
      "a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n",
      "\n",
      "\n",
      "context: Srivatsan is annoyed by a cricket in his room answer: cricket </s>\n",
      "What insect is in Srivatsan's room?\n",
      "cricket\n",
      "['Grasshopper']\n",
      "leaping insect; male makes chirping noises by rubbing the forewings together\n"
     ]
    }
   ],
   "source": [
    "def getMCQs(sent):\n",
    "  sentence_for_bert = sent.replace(\"**\",\" [TGT] \")\n",
    "  sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
    "  # try:\n",
    "  sense,meaning,answer = get_sense(sentence_for_bert)\n",
    "  if sense is not None:\n",
    "    distractors = get_distractors_wordnet(sense,answer)\n",
    "  else: \n",
    "    distractors = [\"Word not found in Wordnet. So unable to extract distractors.\"]\n",
    "  sentence_for_T5 = sent.replace(\"**\",\" \")\n",
    "  sentence_for_T5 = \" \".join(sentence_for_T5.split()) \n",
    "  ques = get_question(sentence_for_T5,answer)\n",
    "  return ques,answer,distractors,meaning\n",
    "\n",
    "\n",
    "\n",
    "print (\"\\n\")\n",
    "question,answer,distractors,meaning = getMCQs(sentence1)\n",
    "print (question)\n",
    "print (answer)\n",
    "print (distractors)\n",
    "print (meaning)\n",
    "\n",
    "print (\"\\n\")\n",
    "question,answer,distractors,meaning = getMCQs(sentence2)\n",
    "print (question)\n",
    "print (answer)\n",
    "print (distractors)\n",
    "print (meaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NI2Y7Qu4eUBq"
   },
   "source": [
    "**Few more examples with disambiguation words (word with contextual meanings)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gp0Sa7EVdqgf",
    "outputId": "171e8c47-e4b5-4f44-c33a-12c99d848b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "context: John went to river bank to cry answer: bank </s>\n",
      "Where did John go to cry?\n",
      "bank\n",
      "['Ascent', 'Canyonside', 'Coast', 'Descent', 'Escarpment', 'Hillside', 'Mountainside', 'Piedmont', 'Ski Slope']\n",
      "sloping land (especially the slope beside a body of water)\n"
     ]
    }
   ],
   "source": [
    "# More examples\n",
    "\n",
    "sentence = \"John went to river **bank** to cry\"\n",
    "# sentence = \"John went to deposit money in the **bank**\"\n",
    "\n",
    "# sentence = \"John bought a **mouse** for his computer.\"\n",
    "# sentence = \"John saw a **mouse** under his bed.\"\n",
    "\n",
    "\n",
    "print (\"\\n\")\n",
    "question,answer,distractors,meaning = getMCQs(sentence)\n",
    "print (question)\n",
    "print (answer)\n",
    "print (distractors)\n",
    "print (meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iIgV34ynlAi3"
   },
   "outputs": [],
   "source": [
    "def mcq_sent(sentence, target):\n",
    "    temp = \"**\" + target + \"**\"\n",
    "    return sentence.replace(target,temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Python variable is a symbolic name that is a...</td>\n",
       "      <td>variable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Exception is an error that happens during t...</td>\n",
       "      <td>Exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning is a method of data analysis ...</td>\n",
       "      <td>machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences            Target\n",
       "0  A Python variable is a symbolic name that is a...          variable\n",
       "1  An Exception is an error that happens during t...         Exception\n",
       "2  Machine learning is a method of data analysis ...  machine learning"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "convert_to_mcq = pd.read_csv(\"/home/utkarsh/Downloads/mcq_generate - Sheet1.csv\")\n",
    "convert_to_mcq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Python variable is a symbolic name that is a reference or pointer to an object. variable\n",
      "context: a python variable is a symbolic name that is a reference or pointer to an object. answer: variable </s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utkarsh/miniconda3/envs/QuestionGenerarion/lib/python3.7/site-packages/transformers/modeling_utils.py:1432: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  beam_id = beam_token_id // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Exception is an error that happens during the execution of a program. Exception\n",
      "context: an exception is an error that happens during the execution of a program. answer: exception </s>\n",
      "Machine learning is a method of data analysis that automates analytical model building. machine learning\n",
      "context: machine learning is a method of data analysis that automates analytical model building. answer: machine learning </s>\n"
     ]
    }
   ],
   "source": [
    "question_list = []\n",
    "answer_list = []\n",
    "mcq_list = []\n",
    "\n",
    "for index, row in convert_to_mcq.iterrows():\n",
    "    print(row[\"Sentences\"], row[\"Target\"])\n",
    "\n",
    "    question, answer, distractors, meaning = getMCQs(mcq_sent(row[\"Sentences\"].lower(), row[\"Target\"].lower()))\n",
    "\n",
    "    question_list.append(question)\n",
    "\n",
    "    if len(distractors) < 2:\n",
    "        mcq = [\"NA\"]\n",
    "    else:\n",
    "        mcq = distractors[:3]\n",
    "        mcq.append(answer)\n",
    "        random.shuffle(mcq)\n",
    "        \n",
    "    mcq_list.append(mcq)\n",
    "\n",
    "    answer_list.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcq_csv_generate(convert_to_mcq):\n",
    "    question_list = []\n",
    "    answer_list = []\n",
    "    mcq_list = []\n",
    "\n",
    "    for index, row in convert_to_mcq.iterrows():\n",
    "        print(row[\"Sentences\"], row[\"Target\"])\n",
    "\n",
    "        question, answer, distractors, meaning = getMCQs(mcq_sent(row[\"Sentences\"].lower(), row[\"Target\"].lower()))\n",
    "\n",
    "        question_list.append(question)\n",
    "\n",
    "        if len(distractors) < 2:\n",
    "            mcq = [\"NA\"]\n",
    "        else:\n",
    "            mcq = distractors[:3]\n",
    "            mcq.append(answer)\n",
    "            random.shuffle(mcq)\n",
    "\n",
    "        mcq_list.append(mcq)\n",
    "\n",
    "        answer_list.append(answer)\n",
    "\n",
    "    dict_ = {\n",
    "            \"Questions\": question_list,\n",
    "            \"Options\": mcq_list,\n",
    "            \"Answers\" : answer_list\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Python variable is a symbolic name that is a reference or pointer to an object. variable\n",
      "context: a python variable is a symbolic name that is a reference or pointer to an object. answer: variable </s>\n",
      "An Exception is an error that happens during the execution of a program. Exception\n",
      "context: an exception is an error that happens during the execution of a program. answer: exception </s>\n",
      "Machine learning is a method of data analysis that automates analytical model building. machine learning\n",
      "context: machine learning is a method of data analysis that automates analytical model building. answer: machine learning </s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Options</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is a symbolic name for an object in python?</td>\n",
       "      <td>[variable, Dollar, Crown, Award]</td>\n",
       "      <td>variable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is an error that happens during the execu...</td>\n",
       "      <td>[Precedent, Apology, Quintessence, exception]</td>\n",
       "      <td>exception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a method of data analysis that automat...</td>\n",
       "      <td>[NA]</td>\n",
       "      <td>machine learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0   What is a symbolic name for an object in python?   \n",
       "1  What is an error that happens during the execu...   \n",
       "2  What is a method of data analysis that automat...   \n",
       "\n",
       "                                         Options           Answers  \n",
       "0               [variable, Dollar, Crown, Award]          variable  \n",
       "1  [Precedent, Apology, Quintessence, exception]         exception  \n",
       "2                                           [NA]  machine learning  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq_csv_generate(convert_to_mcq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is a symbolic name for an object in python?',\n",
       " 'What is an error that happens during the execution of a program?',\n",
       " 'What is a method of data analysis that automates analytical model building?']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['variable', 'exception', 'machine learning']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Crown', 'variable', 'Dollar', 'Award'],\n",
       " ['Apology', 'exception', 'Precedent', 'Quintessence'],\n",
       " ['NA']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "  \n",
    "ct = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {\n",
    "            \"Questions\": question_list,\n",
    "            \"Options\": mcq_list,\n",
    "            \"Answers\" : answer_list\n",
    "        }\n",
    "\n",
    "results = pd.DataFrame(dict_)\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "file = \"./generated_csv/\" + str(ct) + \".csv\"\n",
    "\n",
    "results.to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentence2MCQ using BERT Word Sense Disambiguation and T5 transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('QuestionGenerarion')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad16e0f1c1df2950345d77b428899b9d1e49757cdc4d89c14911b74d168e6f5"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00a5c4c124024b71818660fc555d916d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07624b5f2dcc40228c6a97a81de3ac3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ce1aafc7ed94eaca3809367cb9e2696": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_554bf9faea064f91b95e50a0d45ed377",
      "placeholder": "",
      "style": "IPY_MODEL_c729906924654cf5b6ce0f4332db20d9",
      "value": " 792k/792k [00:00&lt;00:00, 1.81MB/s]"
     }
    },
    "142d016eb8214aa28f19be6b4fbca339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16678cc9ab1a4ba1bc1da2c8a9bde9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e48c134789c4200a3143b077628faed",
      "placeholder": "",
      "style": "IPY_MODEL_a18e76af94ab4101bde6ccb1ba1b3da4",
      "value": " 892M/892M [00:24&lt;00:00, 37.4MB/s]"
     }
    },
    "179becad93544a29b2741191f8bec893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f66d75ab094423d99bb4648b1290698": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00a5c4c124024b71818660fc555d916d",
      "placeholder": "",
      "style": "IPY_MODEL_e309f41ad5184122a86aec00b02ff626",
      "value": "Downloading: 100%"
     }
    },
    "2de42e44240b463f905735646ec5abfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_179becad93544a29b2741191f8bec893",
      "placeholder": "",
      "style": "IPY_MODEL_c5aef9f69ad94c0287ee688fdd10bbb3",
      "value": " 1.21k/1.21k [00:00&lt;00:00, 21.0kB/s]"
     }
    },
    "36a27f29392d4083b8e49c16081d59d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "411d08235cbc429283405673051f88c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7063e4b4cfc24887a83a354033d20a29",
       "IPY_MODEL_e421731c8412433091e58699d9214628",
       "IPY_MODEL_16678cc9ab1a4ba1bc1da2c8a9bde9b6"
      ],
      "layout": "IPY_MODEL_ba839dd8d584448e880b1a2a19554d8f"
     }
    },
    "49fae8c6167b4e2481e73682075e37a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d592c9566f34af9aea2c4d1575fed8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554bf9faea064f91b95e50a0d45ed377": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a94fafe03024a6eaad37959ae64cc73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f66d75ab094423d99bb4648b1290698",
       "IPY_MODEL_fae887e257514fbb801c0c5d331f57c6",
       "IPY_MODEL_2de42e44240b463f905735646ec5abfd"
      ],
      "layout": "IPY_MODEL_142d016eb8214aa28f19be6b4fbca339"
     }
    },
    "6c0840f318024ab9a16fd99fe8767fd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e48c134789c4200a3143b077628faed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "704a5be7508e47449bdc1161a5fe8cd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7063e4b4cfc24887a83a354033d20a29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd5f9302f6284729857f408842194ea4",
      "placeholder": "",
      "style": "IPY_MODEL_704a5be7508e47449bdc1161a5fe8cd4",
      "value": "Downloading: 100%"
     }
    },
    "9b093515743d4e69b216834573f96602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9dbed6d8b4b04194beb3da32d358927d",
       "IPY_MODEL_f4ab9ebc94d84300a0c13ce2b8c93fea",
       "IPY_MODEL_0ce1aafc7ed94eaca3809367cb9e2696"
      ],
      "layout": "IPY_MODEL_f910423ef6e143d1a8a7d95be91bd1b3"
     }
    },
    "9dbed6d8b4b04194beb3da32d358927d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df4c9d848f5c4e0eb29e098e7695c695",
      "placeholder": "",
      "style": "IPY_MODEL_49fae8c6167b4e2481e73682075e37a6",
      "value": "Downloading: 100%"
     }
    },
    "9e6c30f8f75249019d52dd9323421b2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a18e76af94ab4101bde6ccb1ba1b3da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba839dd8d584448e880b1a2a19554d8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5aef9f69ad94c0287ee688fdd10bbb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c729906924654cf5b6ce0f4332db20d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd5f9302f6284729857f408842194ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3fbc0d0728148e3a08dc882bbfc3ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df4c9d848f5c4e0eb29e098e7695c695": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e309f41ad5184122a86aec00b02ff626": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e421731c8412433091e58699d9214628": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d592c9566f34af9aea2c4d1575fed8d",
      "max": 891695056,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07624b5f2dcc40228c6a97a81de3ac3e",
      "value": 891695056
     }
    },
    "f4ab9ebc94d84300a0c13ce2b8c93fea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e6c30f8f75249019d52dd9323421b2e",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36a27f29392d4083b8e49c16081d59d0",
      "value": 791656
     }
    },
    "f910423ef6e143d1a8a7d95be91bd1b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fae887e257514fbb801c0c5d331f57c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3fbc0d0728148e3a08dc882bbfc3ef4",
      "max": 1208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c0840f318024ab9a16fd99fe8767fd3",
      "value": 1208
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
